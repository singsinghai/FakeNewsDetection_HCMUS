{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d387a1b2",
   "metadata": {},
   "source": [
    "# Đồ án 3: Fake news detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7001fed9",
   "metadata": {},
   "source": [
    "## Link trang web đã deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4acbef",
   "metadata": {},
   "source": [
    "[Tại đây](https://share.streamlit.io/dungxibo123/khdl_project3)\n",
    "\n",
    "**Lưu ý**: Trang web có yêu cầu 2 input: văn bản và domain nguồn tin. Đối với domain, ta cần nhập vào domain_raw theo dạng `domain.tên_miền` mà không có https:// hay chứa các dấu '/' (VD: thanhnien.vn thay vì https://thanhnien.vn hoặc thanhnien.vn/nguon_tin.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d3cf07",
   "metadata": {},
   "source": [
    "## Danh sách thành viên"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65677a",
   "metadata": {},
   "source": [
    "| MSSV | Họ Tên | Công việc |\n",
    "| --- | --- | --- |\n",
    "| 1712718 | Huỳnh Thanh Sang | Lựa chọn và xây dựng model phù hợp |\n",
    "| 19120068 | Dương Nam Hải | Lựa chọn và xây dựng model phù hợp |\n",
    "| 19120096 | Lưu Gia Minh | Hợ trợ tiền xử lý dữ liệu, xây dựng streamlit |\n",
    "| 19120202 | Võ Tiến Dũng | Tiền xử lý dữ liệu |\n",
    "| 19120267 | Hoàng Dược Lam | Xây dựng pipeline cho streamlit, viết báo cáo |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f07c95f",
   "metadata": {},
   "source": [
    "## Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79aae8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hailinux/.conda/envs/test/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import preprocessing\n",
    "from preprocessing import *\n",
    "import json\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ddf6f3",
   "metadata": {},
   "source": [
    "## Chiến lược thực hiện"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34723542",
   "metadata": {},
   "source": [
    "Sau khi quan sát tập dữ liệu, nhóm nhận thấy domain của nguồn tin đóng vai trò rất quan trọng trong việc quyết định tin là thật hay giả. Vì thế, chúng em quyết định tạo vector đặc trưng page_rank để đánh giá độ tin cậy của domain. Vector này sẽ có vai trò rất lớn trong việc predict văn bản truyền vào."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc6c93",
   "metadata": {},
   "source": [
    "## Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e477a44b",
   "metadata": {},
   "source": [
    "- Đọc dữ liệu từ file csv và lấy ra 3 thông tin **raw_document**, **raw_domain**, **raw_label**\n",
    "- Trước đó, chúng em đã tiến hành xử lý và chấm điểm độ tin cậy của các domain, lưu trong file `page_rank.json`\n",
    "- Quy đổi điểm của raw_domain dựa vào page_rank.json\n",
    "- Tiền xử lý dữ liệu với các bước sau (thực hiện trong file 'preprocessing.py')\n",
    "    - Chuẩn hóa Unicode tiếng việt - đưa văn bản về chuẩn Unicode đựng sẵn\n",
    "    - Chuyển câu tiếng việt về chuẩn gõ dấu kiểu cũ (dùng `òa úy` thay `oà uý`)\n",
    "    - Tách từ tiếng Việt thành các từ đơn và từ ghép (với sự hỗ trợ của underthesea)\n",
    "    - Đưa toàn bộ văn bản về chữ thường\n",
    "    - Xóa các ký tự không cần thiết (các dấu ngắt câu, số đếm,...)\n",
    "    - Xóa các khoảng trắng thừa\n",
    "    - Loại bỏ các stopword (những từ xuất hiện nhiều trong các văn bản - vì nó không ảnh hưởng đếu hiệu suất của việc phân loại, nên ta có thể bỏ đi để giảm thời gian training model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715566b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.6, 0.0, 0.0, 0.0, 0.0, 2.53, 2.53, 0.0, 0.0, 3.71, 2.31, 2.31, 2.34, 2.31, 0.0, 4.55, 4.55, 0.0, 4.21, 4.53, 4.53, 2.99, 4.6, 0.62, 4.24, 4.24, 0, 4.53, 4.53, 4.53, 4.53, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 2.79, 0.0, 0.0, 4.76, 4.76, 4.76, 4.76, 4.76, 4.78, 5.24, 4.59, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 4.24, 5.15, 5.15, 5.15, 5.15, 4.78, 4.78, 5.24, 5.24, 5.24, 5.24, 4.76, 4.78, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 4.78, 5.24, 4.57, 5.24, 5.24, 5.24, 4.54, 5.24, 5.15, 5.24, 4.57, 5.24, 4.06, 5.24, 5.24, 5.24, 3.65, 3.65, 4.59, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 4.57, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 5.24, 4.24, 4.24, 4.24, 4.24, 4.24, 4.24, 4.24, 4.24, 4.24, 5.23, 5.23, 5.23, 5.23, 5.23, 5.23, 5.23, 5.23, 5.23, 5.23, 5.23, 5.23, 5.23, 5.23]\n"
     ]
    }
   ],
   "source": [
    "# Lấy dữ liệu từ file csv\n",
    "raw_document, raw_domain , raw_label = read_data(\"data/data.csv\") \n",
    "\n",
    "# Lấy phần page_rank đã chấm điểm trước đó\n",
    "f = open(\"page_rank.json\", \"r\")\n",
    "pr = json.loads(''.join(f.readlines()))\n",
    "page_rank = []\n",
    "\n",
    "# Thực hiện đổi phẩn raw_domain thành điểm dựa vào page_rank.json\n",
    "for dm in raw_domain:\n",
    "    try:\n",
    "        page_rank.append(pr[dm])\n",
    "    # Nếu domain không tồn tại trong page_rank.json, điểm của domain sẽ được gán là 0\n",
    "    except KeyError as e:\n",
    "        page_rank.append(0.0)\n",
    "print(page_rank)\n",
    "\n",
    "# Tiền xử lý dữ liệu\n",
    "preprocess_document = list(map(text_preprocess, raw_document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "677c29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết các phần văn bản đã tiền xử lý xuống file txt\n",
    "# Hỗ trợ cho streamlit sau này\n",
    "with open('preprocess_document.txt', 'w') as f:\n",
    "    for item in preprocess_document:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e7a01",
   "metadata": {},
   "source": [
    "Tiến hành Tokenizer văn bản, bằng cách lưu mỗi từ trong toàn bộ văn bản thành 1 ID, sau đó quy đổi các từ trong văn bản thành các ID đã có ở trên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3488cdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 04:43:03.495777: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-09 04:43:03.495794: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_preprocessing.text.Tokenizer object at 0x7fb9fddf0b50>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=15000, \n",
    "                      oov_token='<OOV>', \n",
    "                      filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n')\n",
    "\n",
    "#tokenize toàn bộ văn bản thành \n",
    "tokenihzer.fit_on_texts(preprocess_document)\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "#lấy ra word index, là 1 dict chứa ID và các từ tương ứng\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "#print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "283525d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chuyển các từ trong preprocess_document thành các ID\n",
    "sequences_data = tokenizer.texts_to_sequences(preprocess_document)\n",
    "\n",
    "#Thêm các biến đệm, hoặc loại bỏ dữ liệu\n",
    "#Mục đích: khiến toàn bộ các văn bản có cùng một độ dài chuẩn\n",
    "sequences_data = pad_sequences(sequences_data, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c23d166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "page_rank = np.array(page_rank).reshape(len(page_rank),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7e3e21",
   "metadata": {},
   "source": [
    "Ta chuẩn hóa dữ liệu theo kiểu chuẩn hóa min-max. final_data sẽ có dạng là một ma trận gồm 223 dòng văn bản (đã cung cấp trong data), với mỗi dòng chứa các giá trị sau:\n",
    "\n",
    "- Từ giá trị 0 đến 1849 là thông tin đã được chuẩn hóa\n",
    "- Giá trị 1850 là điểm của domain \n",
    "- Giá trị 1851 là kết quả tin thật hay giả\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c33b9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chuẩn hóa dữ liệu theo chuẩn hóa min-max\n",
    "def normalization(array):\n",
    "    return ( array - np.min(array) ) / (np.max(array) - np.min(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79fa06d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223, 1852)\n"
     ]
    }
   ],
   "source": [
    "# Chuẩn hóa dữ liệu\n",
    "normalized_data = normalization(sequences_data)\n",
    "\n",
    "final_data = np.hstack((normalized_data,\n",
    "                        np.array(page_rank),\n",
    "                        np.array(raw_label).reshape(-1,1).astype(int)))\n",
    "\n",
    "print(final_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e5bc809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09985576, 0.23321868, 0.11683124, ..., 0.        , 2.6       ,\n",
       "        1.        ],\n",
       "       [0.09985576, 0.02474204, 0.11683124, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.26173305, 0.21169422, 0.05702874, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.1765228 , 0.11616554, 0.34916232, ..., 0.        , 5.23      ,\n",
       "        0.        ],\n",
       "       [0.02252302, 0.00288472, 0.07733274, ..., 0.        , 5.23      ,\n",
       "        0.        ],\n",
       "       [0.58959281, 0.06790192, 0.00321757, ..., 0.        , 5.23      ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2ebe402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dữ liệu về file\n",
    "np.savetxt('data/final_data.csv', final_data, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acdbd4d",
   "metadata": {},
   "source": [
    "### Tách thành tập train và test ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556215aa",
   "metadata": {},
   "source": [
    "Tách dữ liệu thành tập train và tập test theo tỷ lệ 80:20, random_state=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a70e88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mydata = np.genfromtxt('data/final_data.csv', delimiter=',')\n",
    "X = mydata[:,:-1]\n",
    "y = mydata[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f43f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "test_percent = 1/5\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=test_percent, \n",
    "                                                    random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ba45d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((178, 1851), (45, 1851), 178, 45)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f9d6c2",
   "metadata": {},
   "source": [
    "## Train model và so sánh kết quả"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc373ed5",
   "metadata": {},
   "source": [
    "Thực hiện training theo 3 model:\n",
    "- Logistic Regression \n",
    "- MLP Classifier\n",
    "- SVM với kernel RBF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e869586",
   "metadata": {},
   "source": [
    "### Logistic Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30d6b48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training Linear Classifier in 0.09663009643554688 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "start_time = time.time()\n",
    "clf = LogisticRegression(solver='lbfgs', \n",
    "                         multi_class='auto', \n",
    "                         max_iter=10000).fit(X_train, y_train)\n",
    " \n",
    "train_time = time.time() - start_time\n",
    "print('Done training Linear Classifier in', train_time, 'seconds.')\n",
    " \n",
    "# Save model\n",
    "pickle.dump(clf, open(\"Model/linear_classifier.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6125dae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9887640449438202, 0.9111111111111111)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,y_train), clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650ec22d",
   "metadata": {},
   "source": [
    "### MLP Classifier ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf01885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.70128353\n",
      "Iteration 2, loss = 0.59516897\n",
      "Iteration 3, loss = 0.42799757\n",
      "Iteration 4, loss = 0.25890119\n",
      "Iteration 5, loss = 0.13928159\n",
      "Iteration 6, loss = 0.07312959\n",
      "Iteration 7, loss = 0.03995604\n",
      "Iteration 8, loss = 0.01923226\n",
      "Iteration 9, loss = 0.00557211\n",
      "Iteration 10, loss = 0.00389161\n",
      "Iteration 11, loss = 0.00305137\n",
      "Iteration 12, loss = 0.00263197\n",
      "Iteration 13, loss = 0.00238609\n",
      "Iteration 14, loss = 0.00226865\n",
      "Iteration 15, loss = 0.00218895\n",
      "Iteration 16, loss = 0.00213142\n",
      "Iteration 17, loss = 0.00207965\n",
      "Iteration 18, loss = 0.00203962\n",
      "Iteration 19, loss = 0.00200683\n",
      "Iteration 20, loss = 0.00197582\n",
      "Iteration 21, loss = 0.00195473\n",
      "Iteration 22, loss = 0.00193588\n",
      "Iteration 23, loss = 0.00191962\n",
      "Iteration 24, loss = 0.00190475\n",
      "Iteration 25, loss = 0.00189209\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Done training MLP Classifier in 37.891682624816895 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(2**11, 2**8, 2**4, 2**3),\n",
    "                    learning_rate='adaptive',\n",
    "                    batch_size=64,\n",
    "                    verbose=True,\n",
    "                    max_iter=100).fit(X_train, y_train)\n",
    "train_time = time.time() - start_time\n",
    "print('Done training MLP Classifier in', train_time, 'seconds.')\n",
    "\n",
    "pickle.dump(clf, open(\"Model/MLP.pkl\", 'wb'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b456bfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.8222222222222222)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,y_train), clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb2751",
   "metadata": {},
   "source": [
    "### SVM với kernel RBF ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37f4d5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done training SVC Classifier in 0.07808637619018555 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "start_time = time.time()\n",
    "clf = SVC(kernel='rbf', gamma=0.001, C=1000).fit(X_train, y_train)\n",
    "train_time = time.time() - start_time\n",
    "print('Done training SVC Classifier in', train_time, 'seconds.')\n",
    "\n",
    "pickle.dump(clf, open('Model/svm_rbf_kernel.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ea4ce1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9111111111111111)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,y_train), clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7caed7",
   "metadata": {},
   "source": [
    "### Đánh giá"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df2f9d",
   "metadata": {},
   "source": [
    "- Cả 3 model với test_size = 20%, đều cho accuracy khá tốt (trên 80%).\n",
    "- Với Logistic Regression và SVM với kernel RBF, 2 model cho accuracy cao hơn so với MLP Classifier. Tuy nhiên, ta chưa đủ căn cứ để đánh giá trong 3 mô hình, mô hình nào thật sự tốt hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6988f2ab",
   "metadata": {},
   "source": [
    "## Xây dựng pipeline cho streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a48a62c",
   "metadata": {},
   "source": [
    "Phần code được thực hiện trong file 'pipeline.py' để hỗ trợ cho việc xây dựng streamlit, gồm các bước như sau:\n",
    "- Đọc dữ liệu đã xử lý từ 'preprocess_document.txt' và tiến hành tokenize.\n",
    "- Từ phần văn bản đã được tokenize, biến đổi phần văn bản nhập vào thành list các ID, thêm các khoảng ID 0 hoặc cắt bớt văn bản sao cho văn bản sau khi xử lý sẽ có độ dài là 1850.\n",
    "- Chuẩn hóa min-max đoạn văn bản đã xử lý .\n",
    "- Tìm điểm của domain và thêm vào cuối array văn bản đã xử lý.\n",
    "- Dự đoán tin thật hay giả và thêm vào cuối array của văn bản."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeb9f36",
   "metadata": {},
   "source": [
    "## Tài liệu tham khảo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc2ea1",
   "metadata": {},
   "source": [
    "- tensorflow, underthesea, scikitlearn, Protonx document\n",
    "- [nguyenvanhieu.vn](https://nguyenvanhieu.vn/phan-loai-van-ban-tieng-viet/?fbclid=IwAR16RSGmJZ67xMQAtv1DR5m8ZsZ5xDFhS31AS9ymm41voL3W392gqCBXrNc#tien-xu-ly-du-lieu-van-ban)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
